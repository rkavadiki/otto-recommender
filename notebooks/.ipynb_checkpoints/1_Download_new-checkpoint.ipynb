{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c8697c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.16.tar.gz (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from kaggle) (6.0.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->kaggle) (0.5.1)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110685 sha256=816c8ed891844f4e5c6198e73266355eeb669ecfc15cb5e3b5e0a41eee035881\n",
      "  Stored in directory: /workspace/.cache/pip/wheels/d2/ed/a5/da3a0cfb13373d1ace41cafa4f2467d858c55c52473ba72799\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.16 python-slugify-8.0.1 text-unidecode-1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e759da1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,time\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e8f29f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2c86a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: line 1: unzip: command not found\n"
     ]
    }
   ],
   "source": [
    "#!kaggle competitions download -c otto-recommender-system -p ../data/\n",
    "#!unzip -q \"../data/otto-recommender-system.zip\" -d ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c48293a-2345-487e-b361-8946e8b43115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(f\"{data_dir}otto-recommender-system.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ddb53b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clicks', 'carts', 'orders'] {'clicks': 0, 'carts': 1, 'orders': 2}\n"
     ]
    }
   ],
   "source": [
    "id2type = ['clicks','carts','orders']\n",
    "type2id = {a:i for i,a in enumerate(id2type)}\n",
    "print(id2type, type2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90de4b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunksize = 100_000\n",
    "def jsontodf(fname,total_chunks,prefix_name,output_directory):\n",
    "    sessions = []\n",
    "    aids = []\n",
    "    tss = []\n",
    "    types =[]\n",
    "    chunks = pd.read_json(fname,lines=True,chunksize=100_000)\n",
    "    for e, chunk in enumerate(tqdm(chunks, total=total_chunks)):\n",
    "        event_dict = {\n",
    "            'session': [],\n",
    "            'aid': [],\n",
    "            'ts': [],\n",
    "            'type': [],\n",
    "        }\n",
    "\n",
    "        for session, events in zip(chunk['session'].tolist(), chunk['events'].tolist()):\n",
    "            for event in events:\n",
    "                event_dict['session'].append(session)\n",
    "                event_dict['aid'].append(event['aid'])\n",
    "                event_dict['ts'].append(event['ts']//1000)\n",
    "                event_dict['type'].append(type2id[event['type']])\n",
    "\n",
    "        # save DataFrame\n",
    "        start = str(e*chunksize).zfill(9)\n",
    "        end = str(e*chunksize+chunksize).zfill(9)\n",
    "        temp = pd.DataFrame(event_dict)\n",
    "        temp[\"type\"] = temp['type'].astype(np.uint8)\n",
    "        temp.ts = temp.ts.astype('int32')\n",
    "        temp.to_parquet(os.path.join(output_directory,f\"{prefix_name}_{start}_{end}.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "788d7322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [17:27<00:00,  8.12s/it]\n"
     ]
    }
   ],
   "source": [
    "jsontodf(os.path.join(data_dir,'train.jsonl'),129,\"train\",os.path.join(data_dir,\"train_pqt_chunks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "556ff1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:45<00:00,  2.66s/it]\n"
     ]
    }
   ],
   "source": [
    "jsontodf(os.path.join(data_dir,'test.jsonl'),17,\"test\",os.path.join(data_dir,\"test_pqt_chunks\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4237dafe-127a-40fc-85e0-70d5ffa8281e",
   "metadata": {},
   "source": [
    "## File for CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ecf83e9-1dee-4b82-9527-52a3c553abc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_train_data():    \n",
    "    dfs = []\n",
    "    for e, chunk_file in enumerate(glob.glob(f'{data_dir}train_pqt_chunks/*')):\n",
    "        chunk = pd.read_parquet(chunk_file)\n",
    "        dfs.append(chunk)\n",
    "        \n",
    "    train_df = pd.concat(dfs).reset_index(drop=True) #.astype({\"ts\": \"datetime64[ms]\"})\n",
    "\n",
    "    # Using different sample as the candidate generation for training\n",
    "    #train_df = train_df[train_df['session']%10 == 1]\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faf5d9eb-06bd-4aca-b065-3fb222bda331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seven_days = 7*24*60*60\n",
    "train = load_train_data()\n",
    "train_cutoff = train.ts.max() - seven_days\n",
    "valid = train[train.ts > train_cutoff]\n",
    "train = train[train.ts <= train_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22646930-7304-4a1a-a81a-e49c45e56e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_cutoff = train.ts.max() - seven_days\n",
    "train_3rdweek = train[train.ts > train_cutoff]\n",
    "train_f2weeks = train[train.ts <= train_cutoff]\n",
    "\n",
    "overlapping_sessions = set(train_f2weeks.session).intersection(set(train_3rdweek.session))\n",
    "train_3rdweek = train_3rdweek[~train_3rdweek.session.isin(overlapping_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95335cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_3rdweek starting from 2022-08-14 22:00:00 and ending at 2022-08-21 21:59:59\n",
      "validation data starting from 2022-08-21 22:00:00 and ending at 2022-08-28 21:59:59\n",
      "sessions between the 2 datasets = 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_3rdweek starting from {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(train_3rdweek.ts.min()))} and ending at {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(train_3rdweek.ts.max()))}\")\n",
    "print(f\"validation data starting from {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(valid.ts.min()))} and ending at {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(valid.ts.max()))}\")\n",
    "print(f\"sessions between the 2 datasets = {len(set(train_f2weeks.session).intersection(set(train_3rdweek.session)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb53bd73-819d-403c-a2cf-28a0009f9e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_3rdweek.to_parquet(f\"{data_dir}local_cv/3week_train_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340d7df4-c42c-4acf-80d6-2106d8a12e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth = valid.groupby(['session', 'type'])['aid'].apply(list)\n",
    "ground_truth = ground_truth.reset_index().rename(columns={'aid': 'labels'})\n",
    "ground_truth.to_parquet(f\"{data_dir}/local_cv/4week_train_labels.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
